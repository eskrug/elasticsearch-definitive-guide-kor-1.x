[[percentiles]]
=== 백분위의 계산

Elasticsearch에 의해 제공되는 또 다른 대략적인 metric은, `percentiles` (백분위) metric이다.((("percentiles")))((("aggregations", "approximate", "percentiles")))((("approximate algorithms", "percentiles"))) 
percentiles는 관찰된 값들 중에서 특정 비율이 나타나는 지점을 나타낸다. 예를 들어, 95번째 percentile는 데이터의 95%보다 더 큰 값이다.

percentiles는 흔히 특이점을 발견하는데 사용한다. (통계적으로) 정규 분포에서, 0.13th과 99.87th의 percentiles는 평균의 세 가지 표준 편차를 나타낸다. 
세 가지 표준 편차에 해당하는 데이터는, 평균 값과 너무 다르기 때문에, 흔히 특이한 것으로 간주된다.

좀 더 구체적으로, 아주 큰 웹사이트가 운영 중이고, 방문자에게 빠른 응답 시간을 보정해 주는 것이 여러분의 업무라고 가정해 보자. 
따라서, 목표의 충족 여부를 확인하기 위해, 웹사이트의 응답 시간을 모니터링 해야 한다.

이 시나리오에 사용하는 공통 metric은 평균 응답 시간이다.((("metrics", "for website latency monitoring")))((("average metric"))) 그러나, 평균(mean)은 특이 사항이 잘 나타나지 않기 때문에, 
실제로는 좋지 않은 선택(일반적인데도 불구하고)이다. 중간 값(median) metric 또한 동일한 문제를 겪는다.((("mean/median metric")))  
최대값(maximum)을 시도하겠지만, 이 metric은 하나의 특이 사항으로 쉽게 왜곡된다.

<<percentile-mean-median>>에 있는 그래프는 그 문제를 보여준다. 평균(mean)이나 중간 값(median) 같은 단순한 metric을 사용한다면, <<percentile-mean-median>>과 같은 그래프를 볼 수 있을 것이다.

[[percentile-mean-median]]
.평균 요청 지연 시간
image::images/elas_33in01.png["평균/중간 값을 이용한 웹사이트 지연시간 평가"]

모든 것이 정상이다. ((("percentiles", "assessing website latency with")))약간 튀는 부분도 있지만, 염려할 것은 없다. 
그러나, 99th percentile(응답 시간이 가장 느린 1%를 차지하는 값)을 알아보면, <<percentile-mean-median-percentile>>에서 볼 수 있듯이, 완전히 다른 이야기를 볼 수 있다.

[[percentile-mean-median-percentile]]
.99th percentiles metric을 사용한 평균 응답시간
image::images/elas_33in02.png["백분위를 이용한 웹사이트 지연시간 평가"]

오전 9:30에, 평균은 겨우 75ms이다. 시스템 관리자로써, 이 값을 반복해서 보지 않을 것이다. 모든 것이 정상이다. 
그러나, 99th percentile은 고객 중 1%의 응답 시간이 850ms를 초과한다고 알려준다. 전혀 다른 이야기이다. 
오전 4:48에도 평균/중간 값에서는 전혀 눈에 띄지도 않는 작은 문제가 있었다.

이것은 percentiles 사용 사례 중의 하나이다. 데이터를 빠르게 검토하거나, 왜곡, 이원화 등을 확인하는데 사용될 수 있다.

==== Percentile Metric

새로운 데이터 집합(자동차 데이터는 percentiles를 테스트하기에 적당하지 않다)을 만들어 보자. 
website의 응답 시간을 색인하고, 거기에 percentiles를 실행한다:

[source,js]
----
POST /website/logs/_bulk
{ "index": {}}
{ "latency" : 100, "zone" : "US", "timestamp" : "2014-10-28" }
{ "index": {}}
{ "latency" : 80, "zone" : "US", "timestamp" : "2014-10-29" }
{ "index": {}}
{ "latency" : 99, "zone" : "US", "timestamp" : "2014-10-29" }
{ "index": {}}
{ "latency" : 102, "zone" : "US", "timestamp" : "2014-10-28" }
{ "index": {}}
{ "latency" : 75, "zone" : "US", "timestamp" : "2014-10-28" }
{ "index": {}}
{ "latency" : 82, "zone" : "US", "timestamp" : "2014-10-29" }
{ "index": {}}
{ "latency" : 100, "zone" : "EU", "timestamp" : "2014-10-28" }
{ "index": {}}
{ "latency" : 280, "zone" : "EU", "timestamp" : "2014-10-29" }
{ "index": {}}
{ "latency" : 155, "zone" : "EU", "timestamp" : "2014-10-29" }
{ "index": {}}
{ "latency" : 623, "zone" : "EU", "timestamp" : "2014-10-28" }
{ "index": {}}
{ "latency" : 380, "zone" : "EU", "timestamp" : "2014-10-28" }
{ "index": {}}
{ "latency" : 319, "zone" : "EU", "timestamp" : "2014-10-29" }
----
// SENSE: 300_Aggregations/65_percentiles.json

이 데이터는 3가지 값(응답 시간-latency, 데이터 센터의 지역-zone, 타임스탬프-timestamp)을 가지고 있다. 
분포의 느낌을 얻기 위해, 전체 데이터 집합에 +percentiles+ 를 실행해 보자:

[source,js]
----
GET /website/logs/_search?search_type=count
{
    "aggs" : {
        "load_times" : {
            "percentiles" : {
                "field" : "latency" <1>
            }
        },
        "avg_load_time" : {
            "avg" : {
                "field" : "latency" <2>
            }
        }
    }
}
----
// SENSE: 300_Aggregations/65_percentiles.json
<1> `percentiles` metric이 +latency+ field에 적용되었다.
<2> 비교하기 위해, 동일한 field에 `avg` metric을 동시에 실행하였다.

기본적으로, `percentiles metric` 은 미리 정의된 percentiles의 배열( `[1, 5, 25, 50, 75, 95, 99]` )을 반환한다. 
이것은 사람들이 관심을 가지는, 일반적인 percentiles(스펙트럼의 끝, 중간의 몇 개중에 극단적인 percentiles)를 나타낸다. 
응답에서 가장 빠른 응답 시간은 약 75ms이다. 반면에 가장 느린 응답 시간은 거의 600ms이다. 반대로, 평균은 거의 200ms이다.((("average metric", "for website latency"))) 거의 도움이 되지 않는다:

[source,js]
----
...
"aggregations": {
  "load_times": {
     "values": {
        "1.0": 75.55,
        "5.0": 77.75,
        "25.0": 94.75,
        "50.0": 101,
        "75.0": 289.75,
        "95.0": 489.34999999999985,
        "99.0": 596.2700000000002
     }
  },
  "avg_load_time": {
     "value": 199.58333333333334
  }
}
----
따라서, 응답 시간에는 분명히 넓은 분포가 있다. 데이터센터의 지리적 위치와 상관관계가 있는지 알아보자:

[source,js]
----
GET /website/logs/_search?search_type=count
{
    "aggs" : {
        "zones" : {
            "terms" : {
                "field" : "zone" <1>
            },
            "aggs" : {
                "load_times" : {
                    "percentiles" : { <2>
                      "field" : "latency",
                      "percents" : [50, 95.0, 99.0] <3>
                    }
                },
                "load_avg" : {
                    "avg" : {
                        "field" : "latency"
                    }
                }
            }
        }
    }
}
----
// SENSE: 300_Aggregations/65_percentiles.json
<1> 먼저, zone에 따라 응답 시간(latency)를 bucket으로 분리한다.
<2> 그 다음에 zone별로 percentiles를 계산한다.
<3> +percents+ 매개변수는 반환될 percentiles의 배열을 가진다. 느린 응답시간에만 관심이 있다.

응답에서, EU지역이 US지역보다 훨씬 더 느린 것을 알 수 있다. US지역에서는 50th percentile이 99th percentile에 거의 근접해 있다. 그리고, 모두 평균에 가깝다.

반면에, EU지역은 50th과 99th percentile 사이에 큰 차이가 있다. EU지역이 지연 시간 metric을 끌어 내리고 있는 것은 분명하다. EU지역 50%의 지연 시간이 300ms 이상인 것을 알 수 있다.

[source,js]
----
...
"aggregations": {
  "zones": {
     "buckets": [
        {
           "key": "eu",
           "doc_count": 6,
           "load_times": {
              "values": {
                 "50.0": 299.5,
                 "95.0": 562.25,
                 "99.0": 610.85
              }
           },
           "load_avg": {
              "value": 309.5
           }
        },
        {
           "key": "us",
           "doc_count": 6,
           "load_times": {
              "values": {
                 "50.0": 90.5,
                 "95.0": 101.5,
                 "99.0": 101.9
              }
           },
           "load_avg": {
              "value": 89.66666666666667
           }
        }
     ]
  }
}
...
----

==== percentile 순위

`percentile_rank` 라 불리는, 밀접하게((("approximate algorithms", "percentiles", "percentile ranks")))((("percentiles", "percentile ranks"))) 연관된 또 하나의 metric이 있다. 
`percentiles` metric은 주어진 document의 비율 아래에 가장 작은 값을 알려준다. 예를 들어, 50th percentile이 119ms이면, document의 50%는 119ms 보다 더 큰 값을 가지지 않는다. `percentile_rank` 는 특정 값에 해당하는 percentile을 알려준다. 
119ms의 `percentile_rank` 는 50th percentile이다. 기본적으로 양방향 관계이다. 
예를 들면:

- 50th percentile은 119ms이다.
- 119ms의 percentile rank는 50th percentile이다.

website가 응답 시간 210ms이하의 SLA 를 유지해야 하고, 그리고, 재미를 위해서, 관리자가 응답 시간이 800ms 이상이면 해고한다는 협박을 하고 있다고 가정해 보자. 
여러분은 당연히 SLA를 충족시키는 요청의 비율을 알고 싶을 것이다(그리고 800ms미만이길 바랄 것이다).

이를 위해, `percentiles` 대신에 `percentile_rank` metric을 적용할 수 있다.

[source,js]
----
GET /website/logs/_search?search_type=count
{
    "aggs" : {
        "zones" : {
            "terms" : {
                "field" : "zone"
            },
            "aggs" : {
                "load_times" : {
                    "percentile_ranks" : {
                      "field" : "latency",
                      "values" : [210, 800] <1>
                    }
                }
            }
        }
    }
}
----
// SENSE: 300_Aggregations/65_percentiles.json
<1> `percentile_rank` metric은 원하는 순위의 값의 배열을 가진다.

이 집계를 실행한 후에, 두 가지 값을 얻을 수 있다:

[source,js]
----
"aggregations": {
  "zones": {
     "buckets": [
        {
           "key": "eu",
           "doc_count": 6,
           "load_times": {
              "values": {
                 "210.0": 31.944444444444443,
                 "800.0": 100
              }
           }
        },
        {
           "key": "us",
           "doc_count": 6,
           "load_times": {
              "values": {
                 "210.0": 100,
                 "800.0": 100
              }
           }
        }
     ]
  }
}
----

여기에서 3가지 중요한 점을 알 수 있다.

* EU지역에서, 210ms에 대한 percentile rank는 31.94%이다.
* US지역에서, 210ms에 대한 percentile rank는 100%이다.
* EU, US 양쪽 지역에서, 800ms에 대한 percentile rank는 100%이다.

쉽게 말하면, EU지역은 SLA의 32%만을 만족시키는데, US지역은 항상 SLA를 만족시킨다. 
그러나, 다행스럽게도, 양쪽 지역 모두 800ms 아래이다. 그래서 해고되지 않을 것이다.(아직은!)

`percentile_rank` metric은 `percentiles` 와 동일한 정보를 제공한다. 
그러나 특정 값에 관심이 있다면, 더 편리한 방법이다.

==== 상충관계의 이해

cardinality와 마찬가지로, percentiles를 계산하는 것은 근사 알고리즘을 필요로 한다.((("percentiles", "understanding the tradeoffs")))((("approximate algorithms", "percentiles", "understanding the tradeoffs"))) 단순하게 구현하면, 모든 값의 정렬된 목록을 유지하는 것이다. 
하지만, 수십 개의 node에 분산된 수십억 개의 값을 가지고 있을 경우, 이것은 불가능하다.

대신, `percentiles` 는 ((("TDigest algorithm")))TDigest(http://bit.ly/1DIpOWK[Computing Extremely Accurate Quantiles Using T-Digests] 에서 Ted Dunning에 의해 소개된)라 불리는 알고리즘을 사용한다. 
HyperLogLog와 마찬가지로, 기술적인 세부사항 전체를 이해할 필요는 없다. 
그러나, 알고리즘의 특성을 알고 있는 것이 좋다:

- percentile의 정밀도는 percentile가 얼마나 _극단적(extreme)_ 인가에 비례한다. 
즉, 1st이나 99th같은 percentiles는 50th보다 더 정확하다. 이것은 단지 데이터의 구조가 동작하는 방법의 특성이지만, 
대부분의 사람들은 극단적인 percentiles에 대해 주의하기 때문에, 좋은 특성이 된다.

- 값이 작은 집합일 경우, percentiles는 매우 정확하다. 데이터 집합이 충분히 작으면, 
percentiles는 100% 정확할 것이다.

- bucket에 있는 값의 양이 증가함에 따라, 알고리즘은 percentiles에 근접하기 시작한다. 
효과적으로 정확성을 메모리 절약과 교환한다. 부정확성의 정확한 수준은, ((("compression parameter (percentiles)"))) 
데이터의 분포나 집계되는 데이터의 양에 따라 달라지기 때문에, 일반화하기 어렵다.((("memory usage", "percentiles, controlling memory/accuracy ratio")))

`cardinality`와 마찬가지로, `compression` 매개변수를 변경하여, 메모리와 정확성의 비율을 제어할 수 있다.

TDigest 알고리즘은 대략적인 percentiles에, node의 수를 사용한다. 이용할 수 있는 node가 많을수록, 데이터의 양에 비례하여, 정확성(과 큰 메모리 공간)이 더 높다. 
compression 매개변수는, `20 * compression` 로, 최대 node 수를 제한한다.

따라서, compression 값을 증가시킴으로써, 더 많은 메모리 비용으로, percentiles의 정확성을 증가시킬 수 있다. 
더 큰 compression 값은 기본 tree 데이터 구조의 크기를 증가시켜, 더 비싼 연산으로 나타나기 때문에, 알고리즘을 느리게 만든다. compression의 기본 값은 `100` 이다.

어떤 node가 대략 32byte의 메모리를 사용한다면, 최악의 시나리오(정리정돈 되어 도착한 많은 양의 데이터)에서, 
기본 설정은 64KB 정도로 TDigest를 생성한다. 실제에서 데이터는 더 무작위이고, TDigest는 더 적은 메모리를 사용할 것이다.
