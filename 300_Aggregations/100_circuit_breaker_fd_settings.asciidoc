
=== 메모리 사용의 제한

집계(또는 field 값을 액세스해야 하는 모든 연산)를 빠르게 하기 위해서는,((("aggregations", "limiting memory usage"))) fielddata가 메모리에 로드되어 있기 때문에, 
fielddata를 액세스하면 빠를 것이다.((("fielddata")))((("memory usage", "limiting for aggregations", id="ix_memagg"))) 그러나, 
너무 많은 데이터를 메모리에 로드하면, JVM이 heap의 여유 공간을 찾으려 하기 때문에, garbage collection을 느리게 하는 원인이 되거나, 
심지어 OutofMemory Exception이 발생할 수 있다.

Elasticsearch가 query에 일치하는 document에 대한 값만을, 
fielddata에 로드 하는 것은 아니다. _index에 있는 모든 document_ , 심지어 다른 `_type` 의 document에 대한 값도 로드한다.

어떤 query로 document X, Y, Z에 액세스해야 한다면, 다음 query에서는 다른 document에 액세스해야 할 것이다. 
모든 값을 한번에 로드 하고, 그것을 _메모리에 유지하는_ 것이, 모든 요청을 inverted index에서 찾는 것보다, 비용이 더 싸다.

JVM의 heap은((("JVM (Java Virtual Machine)", "heap usage, fielddata and"))) 현명하게 사용해야 하는, 제한된 자원이다. 
fielddata의 heap 사용에 미치는 영향을 제한하는, 많은 메커니즘이 존재한다. heap의 남용은 node의 불안정(느린 garbage collection 덕분에)이나, 
다운(OutofMemory Exception)의 원인이기 때문에, 이런 제한은 중요하다. 

.heap 크기의 선택
******************************************

`$ES_HEAP_SIZE` 환경 변수를 가지고, Elasticsearch의 heap size를 설정할((("heap", rules for setting size of"))) 때 적용할, 
두 가지 규칙이 있다:


이용 가능한 RAM의 50% 이상은 불가::
Lucene은 kernel에 의해 관리되는, filesystem cache를 잘 사용한다. 
filesystem cache가 충분하지 않으면, 성능이 저하된다.


32GB 이상은 불가:
heap이 32GB보다 적다면, JVM은 압축 포인터(compressed pointer)사용할 수 있는데, 
이는 많은 메모리를 _절약_한다. pointer당 8byte가 아닌 4byte.


+
heap이 32GB에서 34GB로 증가되면, 모든 포인터가 두 배의 공간을 가지기 때문에, 
이용할 수 있는 메모리가 더 _적어진다_ 는 것을 의미한다. 또한 더 큰 heap은 garbage collection에 
더 많은 비용이 들고, node를 불안정하게 할 수 있다.


이 제한은, fielddata에 사용될 수 있는 많은 메모리에, 직접적인 영향을 준다.

******************************************

[[fielddata-size]]
==== Fielddata의 크기

`indices.fielddata.cache.size` 는 fielddata에 할당되는 heap 공간의 크기를 제어한다.((("fielddata", "size")))((("aggregations", "limiting memory usage", "fielddata size"))) 
새로운 field 값에 액세스하는 것이 필요한, query를 실행하면, 메모리에 값을 로드하고, fielddata에 그것을 추가한다. 
얻어진 fielddata의 크기가 지정된 `size` 를 초과하면, 공간을 마련하기 위해, 다른 값들은 제거될 것이다.

기본적으로 이 설정은 _무제한_ &#x2014;이다. Elasticsearch는 절대로 fielddata에서 다른 값들을 제거하지 않는다.

이 기본값은 고의적으로 선택되었다. fielddata는 일시적인 cache가 아니다. 그것은 빠른 실행을 위해, 
액세스 가능한 메모리에 있는 데이터 구조이고, 구축 비용이 비싸다. 모든 요청에 대해 데이터를 다시 로드 한다면, 성능은 끔찍해질 것이다.

제한된 크기는 데이터 구조에서 데이터를 강제로 제거한다. 아래에서 이 값을 설정하여 검토할 것이다. 
하지만 먼저 주의할 점이 있다:

[WARNING]
=======================================
이 설정은 보호장치이지, 부족한 메모리에 대한 해결책이 아니다.

fielddata를 메모리에 상주시킬 만큼, 메모리가 충분하지 않다면, Elasticsearch는 
항상 디스크에서 데이터를 다시 로드 해야 하고, 공간을 만들기 위해 다른 데이터를 제거해야 한다. 
제거는 많은 디스크 I/O를 가져오고, 메모리에 많은 양의 garbage를 만들어낸다. 
이를 나중에 garbage collection을 통해 정리해야 한다.

=======================================

매일 새로운 index를 사용하여, log를 색인 하는 작업을 가정해 보자. 일반적으로 하루나 이틀 전의 
데이터에만 관심을 가지게 된다. 과거의 index를 보관하겠지만, 그들은 거의 조회되지 않는다. 
그러나, 기본 설정으로 인해, 과거 index의 fielddata는 절대 제거되지 않는다. 
fielddata에 circuit breaker(<<circuit-breaker, 자동 차단기>> 참조)가 작동될 때까지, 
증가를 계속할 것이다. 이것은 더 이상의 fielddata가 로드되는 것을 방지한다.

이 시점에서 문제가 발생한다. 과거 index의 fielddata를 액세스하는 query를 실행할 수 있지만, 
새로운 값을 로드할 수는 없다. 새로운 값을 위한 공간을 만들기 위해, 기존 값을 제거해야 한다.

이런 시나리오를 방지하기 위해, `config/elasticsearch.yml` file에, 아래 설정을 추가하여, 
fielddata의 상한선을 둘 수 있다.

[source,yaml]
-----------------------------
indices.fielddata.cache.size:  40% <1>
-----------------------------
<1> heap 크기의 비율이나, `5GB` 같은 고정 값을 설정할 수 있다.	

이 설정을 하면, 최소한, 최근에 사용된 fielddata는 새로 로드되는 데이터를 위한, 
공간을 만들기 위하여, 제거될 것이다.((("fielddata", "expiry")))

[WARNING]
====
online에서 볼 수 있는 다른 설정( `indices.fielddata.cache.expire` )이 있다.

이 설정을 _절대로_ 사용하지 말라고 부탁한다. 이것은 미래에는 더 이상 사용되지 않을 것이다.

이 설정은 `expire` 보다 더 오래된 값을, 그 값의 사용 여부에 관계없이 fielddata에서 
제거할 것이다.

이것은 성능에 _끔찍한_ 영향을 준다. 제거에는 많은 비용이 들어가는데, 
이것은 실질적인 이점도 없이, 일부러 실질적인 제거를 _계획_ 한다.

이 설정을 사용할 타당한 이유가 없다. 문자 그대로, 가상의 유용한 상황을 이론화할 수도 없다. 그것은 현재, 
과거 버전과의 호환성 때문에 존재한다. 슬프게도, 이 책에서 그 설정을 언급한 이후로, 
인터넷에서 좋은 성능 팁으로, 다양한 글에서 추천되고 있다.

그렇지 않다. 절대 사용하지 말라.
====

[[monitoring-fielddata]]
==== Fielddata 모니터링

fielddata에 얼마나 많은 메모리가((("fielddata", "monitoring")))((("aggregations", "limiting memory usage", "moitoring fielddata"))) 사용되고 있는지, 
그리고 어떤 데이터가 제거되는지, 자세히 관찰해야 한다. 
높은 제거 횟수는 심각한 자원 이슈와 성능 저하의 원인을 가리킨다.

fielddata의 사용량은 다음 API로 관찰 할 수 있다:

* http://www.elastic.co/guide/en/elasticsearch/reference/current/indices-stats.html[`indices-stats` API]를 이용한 index별 관찰:
+
[source,json]
-------------------------------
GET /_stats/fielddata?fields=*
-------------------------------

* http://bit.ly/1586yDn[`nodes-stats` API]를 이용한 index별 관찰:
+
[source,json]
-------------------------------
GET /_nodes/stats/indices/fielddata?fields=*
-------------------------------

* 또는 node별, index 별 관찰

[source,json]
-------------------------------
GET /_nodes/stats/indices/fielddata?level=indices&fields=*
-------------------------------

`?fields=*` 를 설정하면, 메모리 사용량은 각 field로 세분화된다.


[[circuit-breaker]]
==== 자동 차단기

눈치 빠른 독자는, fielddata 크기 설정에 문제가 있음을 알 수 있을 것이다. fielddata 크기는 데이터가 로드된 _후에_ 확인된다.((("aggregations", "limiting memory usage", "fielddata circuit breaker")))  
fielddata에, 이용할 수 있는 메모리보다 더 많이 로드 해야 하는 query가 오면, 어떻게 될까? 당연히, OutOfMemeoy Exception이 발생할 것이다.((("OutOfMemoryException")))((("circuit breakers")))

Elasticsearch는 이런 상황을 처리하기 위하여 설계된, _fielddata circuit breaker_ 를 가지고 있다.((("fielddata circuit breaker"))) 
circuit breaker는 관련된 field(type, cardinality, size 등)를 가로채, query에 필요한 메모리를 추정한다. 그 다음에, 
필요한 fielddata를 총 fielddata의 크기에 넣으면, 설정된 heap의 비율 이상인지를 알아내기 위해 확인한다.

추정된 query 크기가 한계보다 더 크면, circuit breaker가 _작동_ 되고, 
query는 중단되고 exception을 반환한다. 이것은 데이터가 로드되기 _전_ 에 일어난다. 
즉, OutOfMemory Exception이 발생하지 않는다.

.이용 가능한 Circuit Breakers
***************************************

Elasticsearch는 circuit breaker를 여러 개 가지고 있다. 그것 모두는 메모리 한계를 초과하지 않도록 보장한다.

`indices.breaker.fielddata.limit`::

    `fielddata` circuit breaker는 기본적으로, 
    fielddata 의 크기를 heap의 60%로 제한한다. 

`indices.breaker.request.limit`::

    `request` circuit breaker는 요청의 다른 부분을 완성하는데 
    필요한 구조(예: 집계 bucket의 생성)의 크기를 추정하고, 
    기본적으로, 그들을 heap의 40%로 제한한다.

`indices.breaker.total.limit`::

    `total` circuit breaker는 `request` circuit breaker와 
	`fielddata` circuit breaker를 감싸고 있다. 
	기본적으로, 위의 둘의 조합이 heap의 70% 이상을 사용하지 않도록 한다.

***************************************

circuit breaker 제한은 `config/elasticsearch.yml` file에서 지정하거나, 
동작하고 있는 cluster에 동적으로 업데이트될 수 있다.

[source,js]
----
PUT /_cluster/settings
{
  "persistent" : {
    "indices.breaker.fielddata.limit" : "40%" <1>
  }
}
----
<1> 제한은 heap의 백분율로 나타낸다.

상대적으로 보수적인 값으로 circuit breaker를 설정하는 것이 가장 좋다. 
fielddata는, `request` circuit breaker, 색인 메모리 버퍼, filter cache, 
열려 있는 indices를 위한 Lucene의 데이터 구조 그리고 다양한 임시 구조와, 
heap을 공유해야 한다는 점을 기억하자. 이런 이유로, 상당히 보수적인 60%가 기본이다. 
지나치게 낙관적인 설정은 잠재적으로 OutOfMemory Exception을 발생시킬 수 있다. 
이는 전체 node를 다운시킬 것이다.

반면에, 지나치게 보수적인 값은 단순하게 응용프로그램에서 처리될 수 있는 
query를 예외로 반환할 것이다. exception이 crash보다 더 낫다. 
이러한 예외는 query를 다시 검토할 수 있는 기회가 된다. 
왜 이런 query가 heap의 60% 이상을 _사용할까_?

[TIP]
==================================================

<<fielddata-size, fielddata의 크기>>에서, 기존의 사용되지 않은 fielddata를 제거하기 위해, 
fielddata 크기에 제한을 추가하는 것에 대해 이야기했다. `indices.fielddata.cache.size` 와 `indices.breaker.fielddata.limit` 사이의 관계는 중요하다. 
circuit breaker 제한이 cache 크기보다 더 작으면, 데이터는 제거되지 않을 것이다. 정상적으로 동작하기 위해서는 circuit breaker 제한이 cache 크기보다 더 커야 _한다_.

==================================================

circuit breaker가 추정된 query 크기를, 실제 사용된 heap 메모리의 양이 아닌, heap의 총 크기와 비교한다는 점은 중요하다. 
다양한 기술적인 이유 때문에 이렇게 동작한다.(예를 들자면, heap이 가득 찬 것으로 보이지만, 실제로는 garbage가 수집될 것을 기다리고 있다.) 
이것을 적절하게 추정하는 것은 어렵다. 그러나, 최종 사용자로서는 이것이 보수적이어야 한다는 의미이다. 왜냐하면, _남은_ heap이 아닌, 총 heap과 비교하기 때문이다.
((("memory usage", "limiting for aggregations", startref ="ix_memagg")))